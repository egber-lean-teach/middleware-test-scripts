import {
  EmbedContentParameters,
  EmbedContentResponse,
  GenerateContentParameters,
  GoogleGenAI,
} from "@google/genai";
import {
  IOperationType,
  IStreamCompletionRequest,
  IStreamTracker,
  IStreamWrapperRequest,
  ITokenCounts,
} from "@revenium/core";
import {
  calculateDurationMs,
  ESTIMATED_TOKEN_COUNTS,
  extractStopReason,
  generateTransactionId,
  verifyApiKey,
  verifyMeteringConfig,
} from "@revenium/core";
import { logger } from "@revenium/core";
import { extractVertexAITokenCounts } from "@revenium/core";
import { Metering } from "@revenium/core";
export class VertexAIReveniumMiddlewareV2 {
  private client: GoogleGenAI;
  private modelName: string = "";
  private projectId: string;
  private location: string;
  private streamStrackers: Map<string, IStreamTracker> = new Map<
    string,
    IStreamTracker
  >();

  constructor(projectIdClient?: string, locationClient?: string) {
    this.projectId =
      projectIdClient ?? process.env.GOOGLE_CLOUD_PROJECT_ID ?? "";
    this.location =
      locationClient ?? process.env.GOOGLE_CLOUD_LOCATION ?? "us-central1";

    this.client = new GoogleGenAI({
      vertexai: true,
      project: this.projectId,
      location: this.location,
      googleAuthOptions: {
        keyFilename: process.env.GOOGLE_CREDENTIALS,
      },
    });
  }

  public getGenerativeModel(modelName: string) {
    this.modelName = modelName;
    return {
      generateContent: this.generateContentMiddleware,
      generateContentStream: this.generateContentStream,
      embedContent: this.generateEmbedding,
    };
  }

  public generateContentMiddleware = async ({
    request,
    role = "user",
  }: {
    request: string;
    role?: string;
  }) => {
    if (!verifyMeteringConfig()) return;
    const startTime: Date = new Date();
    const transactionId = generateTransactionId();
    const usageMetadata = {};

    logger.info("Vertex AI generateContent called", {
      transactionId,
      model: "test",
    });

    try {
      const result = await this.client.models.generateContent({
        model: this.modelName,
        contents: [
          {
            role,
            parts: [{ text: request }],
          },
        ],
      });
      const tokenCounts: ITokenCounts = extractVertexAITokenCounts(result);
      const stopReason: string = extractStopReason(result);
      const endTime: Date = new Date();
      const metering = new Metering({
        type: "vertex",
      });
      const requestMetering = metering.createMeteringRequest({
        modelName: this.modelName,
        endTime,
        startTime,
        operationType: IOperationType.CHAT,
        stopReason: "END", // is working only END
        tokenCounts,
        usageMetadata,
      });
      await metering.sendMeteringData(requestMetering);
      return result;
    } catch (error) {
      logger.error("Vertex AI generateContent failed", {
        error,
      });
      throw error;
    }
  };

  public generateContentStream = async (params: GenerateContentParameters) => {
    if (!verifyApiKey() || !verifyMeteringConfig()) return;
    const startTime: Date = new Date();
    const transactionId: string = generateTransactionId();
    const usageMetadata = {};

    logger.info("Vertex AI generateContentStream called", {
      transactionId,
      model: this.modelName,
    });

    const streamTracker: IStreamTracker = {
      transactionId,
      startTime,
      firstTokenTime: undefined,
      isComplete: false,
      usageMetadata,
    };
    this.streamStrackers.set(transactionId, streamTracker);

    this.client.models.generateContentStream;

    try {
      const stream = await this.client.models.generateContentStream({
        ...params,
        model: this.modelName,
      });
      const wrappedStream = this.createStreamWrapper({
        originalStream: stream,
        transactionId,
        startTime,
        streamTracker,
        usageMetadata,
      });
      return wrappedStream;
    } catch (error) {
      logger.error("Vertex AI generateContentStream failed", {
        error,
      });
      throw error;
    }
  };

  private createStreamWrapper = (
    streamRequest: IStreamWrapperRequest
  ): AsyncIterable<any> => {
    const _this = this;
    return {
      [Symbol.asyncIterator]: async function* () {
        let isFirstToken = true;
        let firstTokenTime: Date | undefined;

        try {
          for await (const chunk of streamRequest.originalStream) {
            if (isFirstToken) {
              firstTokenTime = new Date();
              streamRequest.streamTracker.firstTokenTime = firstTokenTime;
              isFirstToken = false;
            }
            yield chunk;
          }
        } finally {
          await _this.handleStreamCompletion({
            transactionId: streamRequest.transactionId,
            startTime: streamRequest.startTime,
            firstTokenTime,
            modelName: _this.modelName,
            usageMetadata: streamRequest.usageMetadata,
          });
        }
      },
    };
  };

  private handleStreamCompletion = async (
    request: IStreamCompletionRequest
  ) => {
    try {
      const streamTracker = this.streamStrackers.get(request.transactionId);
      if (!streamTracker) {
        logger.warning("Stream tracker not found for transaction", {
          transactionId: request.transactionId,
        });
        return;
      }
      const endTime: Date = new Date();
      const duration: number = calculateDurationMs(request.startTime, endTime);
      const timeToFirstToken: number = request.firstTokenTime
        ? calculateDurationMs(request.startTime, request.firstTokenTime)
        : 0;
      const metering = new Metering({
        type: "vertex",
      });
      const meteringRequest = metering.createMeteringRequest({
        modelName: this.modelName,
        endTime,
        startTime: request.startTime,
        operationType: IOperationType.CHAT,
        stopReason: "END",
        tokenCounts: ESTIMATED_TOKEN_COUNTS,
        usageMetadata: request.usageMetadata,
      });
      await metering.sendMeteringData(meteringRequest);
      this.streamStrackers.delete(request.transactionId);
      logger.info("Vertex AI stream completion metering completed", {
        transactionId: request.transactionId,
      });
    } catch (error: any) {
      logger.error("Failed to handle stream completion metering", {
        transactionId: request.transactionId,
        error,
      });
      this.streamStrackers.delete(request.transactionId);
    }
  };

  public generateEmbedding = async (
    params: Omit<EmbedContentParameters, "model">
  ): Promise<EmbedContentResponse | undefined> => {
    if (!verifyApiKey() || !verifyMeteringConfig()) return;
    const startTime: Date = new Date();
    const transactionId = generateTransactionId();
    const usageMetadata = {};

    logger.info("Vertex AI embedContent called", {
      transactionId,
      model: this.modelName,
    });

    try {
      const result = await this.client.models.embedContent({
        ...params,
        model: this.modelName,
        config: {
          outputDimensionality: 768,
        },
      });
      const endTime: Date = new Date();
      const metering = new Metering({
        type: "vertex",
      });
      const meteringRequest = metering.createMeteringRequest({
        modelName: this.modelName,
        endTime,
        startTime,
        operationType: IOperationType.EMBED,
        stopReason: "END",
        tokenCounts: ESTIMATED_TOKEN_COUNTS,
        usageMetadata,
      });
      await metering.sendMeteringData(meteringRequest);
      return result;
    } catch (error: any) {
      logger.error("Vertex AI generateEmbedding failed", {
        error,
      });
      throw error;
    }
  };
}
