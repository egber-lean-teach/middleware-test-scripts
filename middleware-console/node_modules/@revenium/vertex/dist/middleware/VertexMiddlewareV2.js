"use strict";
Object.defineProperty(exports, "__esModule", { value: true });
exports.VertexAIReveniumMiddlewareV2 = void 0;
const genai_1 = require("@google/genai");
const core_1 = require("@revenium/core");
const core_2 = require("@revenium/core");
const core_3 = require("@revenium/core");
const core_4 = require("@revenium/core");
const core_5 = require("@revenium/core");
class VertexAIReveniumMiddlewareV2 {
    constructor(projectIdClient, locationClient) {
        var _a, _b;
        this.modelName = "";
        this.streamStrackers = new Map();
        this.generateContentMiddleware = async ({ request, role = "user", }) => {
            if (!(0, core_2.verifyMeteringConfig)())
                return;
            const startTime = new Date();
            const transactionId = (0, core_2.generateTransactionId)();
            const usageMetadata = {};
            core_3.logger.info("Vertex AI generateContent called", {
                transactionId,
                model: "test",
            });
            try {
                const result = await this.client.models.generateContent({
                    model: this.modelName,
                    contents: [
                        {
                            role,
                            parts: [{ text: request }],
                        },
                    ],
                });
                const tokenCounts = (0, core_4.extractVertexAITokenCounts)(result);
                const stopReason = (0, core_2.extractStopReason)(result);
                const endTime = new Date();
                const metering = new core_5.Metering({
                    type: "vertex",
                });
                const requestMetering = metering.createMeteringRequest({
                    modelName: this.modelName,
                    endTime,
                    startTime,
                    operationType: core_1.IOperationType.CHAT,
                    stopReason: "END", // is working only END
                    tokenCounts,
                    usageMetadata,
                });
                await metering.sendMeteringData(requestMetering);
                return result;
            }
            catch (error) {
                core_3.logger.error("Vertex AI generateContent failed", {
                    error,
                });
                throw error;
            }
        };
        this.generateContentStream = async (params) => {
            if (!(0, core_2.verifyApiKey)() || !(0, core_2.verifyMeteringConfig)())
                return;
            const startTime = new Date();
            const transactionId = (0, core_2.generateTransactionId)();
            const usageMetadata = {};
            core_3.logger.info("Vertex AI generateContentStream called", {
                transactionId,
                model: this.modelName,
            });
            const streamTracker = {
                transactionId,
                startTime,
                firstTokenTime: undefined,
                isComplete: false,
                usageMetadata,
            };
            this.streamStrackers.set(transactionId, streamTracker);
            this.client.models.generateContentStream;
            try {
                const stream = await this.client.models.generateContentStream({
                    ...params,
                    model: this.modelName,
                });
                const wrappedStream = this.createStreamWrapper({
                    originalStream: stream,
                    transactionId,
                    startTime,
                    streamTracker,
                    usageMetadata,
                });
                return wrappedStream;
            }
            catch (error) {
                core_3.logger.error("Vertex AI generateContentStream failed", {
                    error,
                });
                throw error;
            }
        };
        this.createStreamWrapper = (streamRequest) => {
            const _this = this;
            return {
                [Symbol.asyncIterator]: async function* () {
                    let isFirstToken = true;
                    let firstTokenTime;
                    try {
                        for await (const chunk of streamRequest.originalStream) {
                            if (isFirstToken) {
                                firstTokenTime = new Date();
                                streamRequest.streamTracker.firstTokenTime = firstTokenTime;
                                isFirstToken = false;
                            }
                            yield chunk;
                        }
                    }
                    finally {
                        await _this.handleStreamCompletion({
                            transactionId: streamRequest.transactionId,
                            startTime: streamRequest.startTime,
                            firstTokenTime,
                            modelName: _this.modelName,
                            usageMetadata: streamRequest.usageMetadata,
                        });
                    }
                },
            };
        };
        this.handleStreamCompletion = async (request) => {
            try {
                const streamTracker = this.streamStrackers.get(request.transactionId);
                if (!streamTracker) {
                    core_3.logger.warning("Stream tracker not found for transaction", {
                        transactionId: request.transactionId,
                    });
                    return;
                }
                const endTime = new Date();
                const duration = (0, core_2.calculateDurationMs)(request.startTime, endTime);
                const timeToFirstToken = request.firstTokenTime
                    ? (0, core_2.calculateDurationMs)(request.startTime, request.firstTokenTime)
                    : 0;
                const metering = new core_5.Metering({
                    type: "vertex",
                });
                const meteringRequest = metering.createMeteringRequest({
                    modelName: this.modelName,
                    endTime,
                    startTime: request.startTime,
                    operationType: core_1.IOperationType.CHAT,
                    stopReason: "END",
                    tokenCounts: core_2.ESTIMATED_TOKEN_COUNTS,
                    usageMetadata: request.usageMetadata,
                });
                await metering.sendMeteringData(meteringRequest);
                this.streamStrackers.delete(request.transactionId);
                core_3.logger.info("Vertex AI stream completion metering completed", {
                    transactionId: request.transactionId,
                });
            }
            catch (error) {
                core_3.logger.error("Failed to handle stream completion metering", {
                    transactionId: request.transactionId,
                    error,
                });
                this.streamStrackers.delete(request.transactionId);
            }
        };
        this.generateEmbedding = async (params) => {
            if (!(0, core_2.verifyApiKey)() || !(0, core_2.verifyMeteringConfig)())
                return;
            const startTime = new Date();
            const transactionId = (0, core_2.generateTransactionId)();
            const usageMetadata = {};
            core_3.logger.info("Vertex AI embedContent called", {
                transactionId,
                model: this.modelName,
            });
            try {
                const result = await this.client.models.embedContent({
                    ...params,
                    model: this.modelName,
                    config: {
                        outputDimensionality: 768,
                    },
                });
                const endTime = new Date();
                const metering = new core_5.Metering({
                    type: "vertex",
                });
                const meteringRequest = metering.createMeteringRequest({
                    modelName: this.modelName,
                    endTime,
                    startTime,
                    operationType: core_1.IOperationType.EMBED,
                    stopReason: "END",
                    tokenCounts: core_2.ESTIMATED_TOKEN_COUNTS,
                    usageMetadata,
                });
                await metering.sendMeteringData(meteringRequest);
                return result;
            }
            catch (error) {
                core_3.logger.error("Vertex AI generateEmbedding failed", {
                    error,
                });
                throw error;
            }
        };
        this.projectId =
            (_a = projectIdClient !== null && projectIdClient !== void 0 ? projectIdClient : process.env.GOOGLE_CLOUD_PROJECT_ID) !== null && _a !== void 0 ? _a : "";
        this.location =
            (_b = locationClient !== null && locationClient !== void 0 ? locationClient : process.env.GOOGLE_CLOUD_LOCATION) !== null && _b !== void 0 ? _b : "us-central1";
        this.client = new genai_1.GoogleGenAI({
            vertexai: true,
            project: this.projectId,
            location: this.location,
            googleAuthOptions: {
                keyFilename: process.env.GOOGLE_CREDENTIALS,
            },
        });
    }
    getGenerativeModel(modelName) {
        this.modelName = modelName;
        return {
            generateContent: this.generateContentMiddleware,
            generateContentStream: this.generateContentStream,
            embedContent: this.generateEmbedding,
        };
    }
}
exports.VertexAIReveniumMiddlewareV2 = VertexAIReveniumMiddlewareV2;
