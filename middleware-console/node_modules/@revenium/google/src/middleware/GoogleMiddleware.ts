import { config } from "dotenv";
import {
  GoogleGenAI,
  GenerateContentParameters,
  EmbedContentParameters,
} from "@google/genai";
import {
  IOperationType,
  IStreamCompletionRequest,
  IStreamTracker,
  IStreamWrapperRequest,
  ITokenCounts,
  calculateDurationMs,
  ESTIMATED_TOKEN_COUNTS,
  extractGoogleAITokenCounts,
  extractStopReason,
  generateTransactionId,
  logger,
  Metering,
  verifyApiKey,
  verifyMeteringConfig,
  extractModelName,
} from "@revenium/core";

config();

export class GoogleAiReveniumMiddleware {
  private apikey: string | undefined = "";
  private client: GoogleGenAI;
  private modelName: string = "";
  private streamStrackers: Map<string, IStreamTracker> = new Map<
    string,
    IStreamTracker
  >();

  constructor(clientApiKey?: string) {
    this.apikey = clientApiKey ?? process.env.GOOGLE_API_KEY;
    this.client = new GoogleGenAI({
      apiKey: this.apikey ?? process.env.GOOGLE_API_KEY ?? "",
    });
  }

  public getGenerativeModel(modelPrams: { model: string }) {
    this.modelName = modelPrams.model;
    return {
      generateContent: this.generateContentMiddleware,
      generateContentStream: this.generateContentStream,
      embedContent: this.generateEmbedding,
    };
  }

  generateContentMiddleware = async (
    request: string | GenerateContentParameters
  ) => {
    if (!verifyApiKey() || !verifyMeteringConfig()) return;
    const startTime: Date = new Date();

    try {
      const params: GenerateContentParameters =
        typeof request === "string"
          ? {
              model: this.modelName,
              contents: [{ role: "user", parts: [{ text: request }] }],
            }
          : { ...request, model: this.modelName };
      const content = await this.client.models.generateContent(params);

      const tokenCounts: ITokenCounts = extractGoogleAITokenCounts(content);
      const stopReason: string = extractStopReason(content);
      const endTime: Date = new Date();
      if (
        !process.env.REVENIUM_METERING_API_KEY ||
        !process.env.REVENIUM_METERING_BASE_URL
      )
        return;

      const metering = new Metering();
      const requestMetering = metering.createMeteringRequest({
        modelName: this.modelName,
        endTime,
        startTime,
        operationType: IOperationType.CHAT,
        stopReason: "END", // is workind only with END
        tokenCounts,
        usageMetadata: {},
      });
      await metering.sendMeteringData(requestMetering);
      return content;
    } catch (error: any) {
      logger.error("Google AI generateContent failed", {
        error,
      });
      throw error;
    }
  };

  generateContentStream = async (
    request: string | GenerateContentParameters
  ) => {
    if (!verifyApiKey() || !verifyMeteringConfig()) return;
    const startTime: Date = new Date();
    const transactionId: string = generateTransactionId();
    const usageMetadata = {};

    logger.info("Google AI generateContentStream called", {
      transactionId,
      model: this.modelName,
    });

    const streamTracker: IStreamTracker = {
      transactionId,
      startTime,
      firstTokenTime: undefined,
      isComplete: false,
      usageMetadata,
    };
    this.streamStrackers.set(transactionId, streamTracker);

    try {
      const params: GenerateContentParameters =
        typeof request === "string"
          ? {
              model: this.modelName,
              contents: [{ role: "user", parts: [{ text: request }] }],
            }
          : { ...request, model: this.modelName };

      const result = await this.client.models.generateContentStream(params);

      const wrappedStream = this.createStreamWrapper({
        originalStream: result,
        transactionId,
        startTime,
        streamTracker,
        usageMetadata,
      });
      return wrappedStream;
    } catch (error: any) {
      this.streamStrackers.delete(transactionId);
      logger.error("Google AI generateContentStream failed", {
        transactionId,
        error,
      });
      throw error;
    }
  };

  private createStreamWrapper = (
    streamRequest: IStreamWrapperRequest
  ): AsyncIterable<any> => {
    const _this = this;
    return {
      [Symbol.asyncIterator]: async function* () {
        let isFirstToken = true;
        let firstTokenTime: Date | undefined;

        try {
          for await (const chunk of streamRequest.originalStream) {
            if (isFirstToken) {
              firstTokenTime = new Date();
              streamRequest.streamTracker.firstTokenTime = firstTokenTime;
              isFirstToken = false;
            }
            yield chunk;
          }
        } finally {
          await _this.handleStreamCompletion({
            transactionId: streamRequest.transactionId,
            startTime: streamRequest.startTime,
            firstTokenTime,
            modelName: _this.modelName,
            usageMetadata: streamRequest.usageMetadata,
          });
        }
      },
    };
  };

  private handleStreamCompletion = async (
    request: IStreamCompletionRequest
  ) => {
    try {
      const streamTracker = this.streamStrackers.get(request.transactionId);
      if (!streamTracker) {
        logger.warning("Stream tracker not found for transaction", {
          transactionId: request.transactionId,
        });
        return;
      }
      const endTime: Date = new Date();
      const duration: number = calculateDurationMs(request.startTime, endTime);
      const timeToFirstToken: number = request.firstTokenTime
        ? calculateDurationMs(request.startTime, request.firstTokenTime)
        : 0;
      const metering = new Metering();
      const meteringRequest = metering.createMeteringRequest({
        modelName: this.modelName,
        endTime,
        startTime: request.startTime,
        operationType: IOperationType.CHAT,
        stopReason: "END",
        tokenCounts: ESTIMATED_TOKEN_COUNTS,
        usageMetadata: request.usageMetadata,
      });
      await metering.sendMeteringData(meteringRequest);
      this.streamStrackers.delete(request.transactionId);
      logger.info("Google AI stream completion metering completed", {
        transactionId: request.transactionId,
      });
    } catch (error: any) {
      logger.error("Failed to handle stream completion metering", {
        transactionId: request.transactionId,
        error,
      });
      this.streamStrackers.delete(request.transactionId);
    }
  };

  generateEmbedding = async (request: string | EmbedContentParameters) => {
    if (!verifyApiKey() || !verifyMeteringConfig()) return;
    logger.info("Google AI embedContent called");
    const startTime: Date = new Date();
    const transactionId = generateTransactionId();
    const model = this.modelName;
    const usageMetadata = {};

    logger.info("Google AI embedContent called", {
      transactionId,
      model,
    });

    try {
      const params: EmbedContentParameters =
        typeof request === "string"
          ? { model: this.modelName, contents: [request] }
          : { ...request, model: this.modelName };

      const result = await this.client.models.embedContent(params);
      const stopReason = extractStopReason(result);
      const endTime: Date = new Date();

      const metering = new Metering();
      const meteringRequest = metering.createMeteringRequest({
        modelName: this.modelName,
        endTime,
        startTime,
        operationType: IOperationType.EMBED,
        stopReason,
        tokenCounts: ESTIMATED_TOKEN_COUNTS,
        usageMetadata,
      });
      await metering.sendMeteringData(meteringRequest);
      return result;
    } catch (error: any) {
      logger.error("Google AI embedContent failed", {
        error,
      });
      throw error;
    }
  };
}
