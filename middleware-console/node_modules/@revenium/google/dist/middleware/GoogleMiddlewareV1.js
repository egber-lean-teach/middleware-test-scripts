"use strict";
Object.defineProperty(exports, "__esModule", { value: true });
exports.GoogleAiReveniumMiddlewareV1 = void 0;
const dotenv_1 = require("dotenv");
const generative_ai_1 = require("@google/generative-ai");
const core_1 = require("@revenium/core");
(0, dotenv_1.config)();
class GoogleAiReveniumMiddlewareV1 {
    constructor(clientApiKey) {
        var _a;
        this.apikey = "";
        this.streamStrackers = new Map();
        this.generateContentMiddleware = async (request, requestOptions) => {
            core_1.logger.info("--- Middleware actived ---");
            if (!(0, core_1.verifyApiKey)() || !(0, core_1.verifyMeteringConfig)())
                return;
            const startTime = new Date();
            try {
                const content = await this.model.generateContent(request, requestOptions);
                const tokenCounts = (0, core_1.extractGoogleAITokenCounts)(content);
                const stopReason = (0, core_1.extractStopReason)(content);
                const endTime = new Date();
                if (!process.env.REVENIUM_METERING_API_KEY ||
                    !process.env.REVENIUM_METERING_BASE_URL)
                    return;
                const metering = new core_1.Metering();
                const requestMetering = metering.createMeteringRequest({
                    modelName: this.model.model.split("models/")[1],
                    endTime,
                    startTime,
                    operationType: core_1.IOperationType.CHAT,
                    stopReason,
                    tokenCounts,
                    usageMetadata: {},
                });
                await metering.sendMeteringData(requestMetering);
                return content;
            }
            catch (error) {
                core_1.logger.error("Google AI generateContent failed", {
                    error,
                });
                throw error;
            }
        };
        this.generateContentStream = async (request, requestOptions) => {
            if (!(0, core_1.verifyApiKey)() || !(0, core_1.verifyMeteringConfig)())
                return;
            const startTime = new Date();
            const transactionId = (0, core_1.generateTransactionId)();
            const usageMetadata = {};
            core_1.logger.info("Google AI generateContentStream called", {
                transactionId,
                model: this.model.model,
            });
            const streamTracker = {
                transactionId,
                startTime,
                firstTokenTime: undefined,
                isComplete: false,
                usageMetadata,
            };
            this.streamStrackers.set(transactionId, streamTracker);
            try {
                const result = await this.model.generateContentStream(request, requestOptions);
                const wrappedStream = this.createStreamWrapper({
                    originalStream: result.stream,
                    transactionId,
                    startTime,
                    streamTracker,
                    usageMetadata,
                });
                Object.defineProperty(result, "stream", {
                    value: wrappedStream,
                    writable: false,
                    configurable: false,
                });
                return result;
            }
            catch (error) {
                this.streamStrackers.delete(transactionId);
                core_1.logger.error("Google AI generateContentStream failed", {
                    transactionId,
                    error,
                });
                throw error;
            }
        };
        this.createStreamWrapper = (streamRequest) => {
            const _this = this;
            return {
                [Symbol.asyncIterator]: async function* () {
                    var _a, _b;
                    let isFirstToken = true;
                    let firstTokenTime;
                    try {
                        for await (const chunk of streamRequest.originalStream) {
                            if (isFirstToken) {
                                firstTokenTime = new Date();
                                streamRequest.streamTracker.firstTokenTime = firstTokenTime;
                                isFirstToken = false;
                            }
                            yield chunk;
                        }
                    }
                    finally {
                        await _this.handleStreamCompletion({
                            transactionId: streamRequest.transactionId,
                            startTime: streamRequest.startTime,
                            firstTokenTime,
                            modelName: (_b = (_a = _this.model) === null || _a === void 0 ? void 0 : _a.model) === null || _b === void 0 ? void 0 : _b.split("models/")[1],
                            usageMetadata: streamRequest.usageMetadata,
                        });
                    }
                },
            };
        };
        this.handleStreamCompletion = async (request) => {
            try {
                const streamTracker = this.streamStrackers.get(request.transactionId);
                if (!streamTracker) {
                    core_1.logger.warning("Stream tracker not found for transaction", {
                        transactionId: request.transactionId,
                    });
                    return;
                }
                const endTime = new Date();
                const duration = (0, core_1.calculateDurationMs)(request.startTime, endTime);
                const timeToFirstToken = request.firstTokenTime
                    ? (0, core_1.calculateDurationMs)(request.startTime, request.firstTokenTime)
                    : 0;
                const metering = new core_1.Metering();
                const meteringRequest = metering.createMeteringRequest({
                    modelName: this.model.model.split("models/")[1],
                    endTime,
                    startTime: request.startTime,
                    operationType: core_1.IOperationType.CHAT,
                    stopReason: "END",
                    tokenCounts: core_1.ESTIMATED_TOKEN_COUNTS,
                    usageMetadata: request.usageMetadata,
                });
                await metering.sendMeteringData(meteringRequest);
                this.streamStrackers.delete(request.transactionId);
                core_1.logger.info("Google AI stream completion metering completed", {
                    transactionId: request.transactionId,
                });
            }
            catch (error) {
                core_1.logger.error("Failed to handle stream completion metering", {
                    transactionId: request.transactionId,
                    error,
                });
                this.streamStrackers.delete(request.transactionId);
            }
        };
        this.generateEmbedding = async (request, requestOptions) => {
            if (!(0, core_1.verifyApiKey)() || !(0, core_1.verifyMeteringConfig)())
                return;
            core_1.logger.info("Google AI embedContent called");
            const startTime = new Date();
            const transactionId = (0, core_1.generateTransactionId)();
            const model = this.model.model.split("models/")[1];
            const usageMetadata = {};
            core_1.logger.info("Google AI embedContent called", {
                transactionId,
                model,
            });
            try {
                const result = await this.model.embedContent(request, requestOptions);
                const stopReason = (0, core_1.extractStopReason)(result);
                const modelName = (0, core_1.extractModelName)(result, model);
                const endTime = new Date();
                const metering = new core_1.Metering();
                const meteringRequest = metering.createMeteringRequest({
                    modelName,
                    endTime,
                    startTime,
                    operationType: core_1.IOperationType.EMBED,
                    stopReason,
                    tokenCounts: core_1.ESTIMATED_TOKEN_COUNTS,
                    usageMetadata,
                });
                await metering.sendMeteringData(meteringRequest);
                return result;
            }
            catch (error) {
                core_1.logger.error("Google AI embedContent failed", {
                    error,
                });
                throw error;
            }
        };
        this.apikey = clientApiKey !== null && clientApiKey !== void 0 ? clientApiKey : process.env.GOOGLE_API_KEY;
        this.client = new generative_ai_1.GoogleGenerativeAI((_a = clientApiKey !== null && clientApiKey !== void 0 ? clientApiKey : process.env.GOOGLE_API_KEY) !== null && _a !== void 0 ? _a : "");
    }
    getGenerativeModel(modelParams, requestOptions) {
        const model = this.client.getGenerativeModel(modelParams, requestOptions);
        this.model = model;
        return {
            ...model,
            generateContent: this.generateContentMiddleware,
            generateContentStream: this.generateContentStream,
            embedContent: this.generateEmbedding,
        };
    }
}
exports.GoogleAiReveniumMiddlewareV1 = GoogleAiReveniumMiddlewareV1;
