"use strict";
Object.defineProperty(exports, "__esModule", { value: true });
exports.GoogleAiReveniumMiddleware = void 0;
const dotenv_1 = require("dotenv");
const genai_1 = require("@google/genai");
const core_1 = require("@revenium/core");
(0, dotenv_1.config)();
class GoogleAiReveniumMiddleware {
    constructor(clientApiKey) {
        var _a, _b;
        this.apikey = "";
        this.modelName = "";
        this.streamStrackers = new Map();
        this.generateContentMiddleware = async (request) => {
            if (!(0, core_1.verifyApiKey)() || !(0, core_1.verifyMeteringConfig)())
                return;
            const startTime = new Date();
            try {
                const params = typeof request === "string"
                    ? {
                        model: this.modelName,
                        contents: [{ role: "user", parts: [{ text: request }] }],
                    }
                    : { ...request, model: this.modelName };
                const content = await this.client.models.generateContent(params);
                const tokenCounts = (0, core_1.extractGoogleAITokenCounts)(content);
                const stopReason = (0, core_1.extractStopReason)(content);
                const endTime = new Date();
                if (!process.env.REVENIUM_METERING_API_KEY ||
                    !process.env.REVENIUM_METERING_BASE_URL)
                    return;
                const metering = new core_1.Metering();
                const requestMetering = metering.createMeteringRequest({
                    modelName: this.modelName,
                    endTime,
                    startTime,
                    operationType: core_1.IOperationType.CHAT,
                    stopReason: "END", // is workind only with END
                    tokenCounts,
                    usageMetadata: {},
                });
                await metering.sendMeteringData(requestMetering);
                return content;
            }
            catch (error) {
                core_1.logger.error("Google AI generateContent failed", {
                    error,
                });
                throw error;
            }
        };
        this.generateContentStream = async (request) => {
            if (!(0, core_1.verifyApiKey)() || !(0, core_1.verifyMeteringConfig)())
                return;
            const startTime = new Date();
            const transactionId = (0, core_1.generateTransactionId)();
            const usageMetadata = {};
            core_1.logger.info("Google AI generateContentStream called", {
                transactionId,
                model: this.modelName,
            });
            const streamTracker = {
                transactionId,
                startTime,
                firstTokenTime: undefined,
                isComplete: false,
                usageMetadata,
            };
            this.streamStrackers.set(transactionId, streamTracker);
            try {
                const params = typeof request === "string"
                    ? {
                        model: this.modelName,
                        contents: [{ role: "user", parts: [{ text: request }] }],
                    }
                    : { ...request, model: this.modelName };
                const result = await this.client.models.generateContentStream(params);
                const wrappedStream = this.createStreamWrapper({
                    originalStream: result,
                    transactionId,
                    startTime,
                    streamTracker,
                    usageMetadata,
                });
                return wrappedStream;
            }
            catch (error) {
                this.streamStrackers.delete(transactionId);
                core_1.logger.error("Google AI generateContentStream failed", {
                    transactionId,
                    error,
                });
                throw error;
            }
        };
        this.createStreamWrapper = (streamRequest) => {
            const _this = this;
            return {
                [Symbol.asyncIterator]: async function* () {
                    let isFirstToken = true;
                    let firstTokenTime;
                    try {
                        for await (const chunk of streamRequest.originalStream) {
                            if (isFirstToken) {
                                firstTokenTime = new Date();
                                streamRequest.streamTracker.firstTokenTime = firstTokenTime;
                                isFirstToken = false;
                            }
                            yield chunk;
                        }
                    }
                    finally {
                        await _this.handleStreamCompletion({
                            transactionId: streamRequest.transactionId,
                            startTime: streamRequest.startTime,
                            firstTokenTime,
                            modelName: _this.modelName,
                            usageMetadata: streamRequest.usageMetadata,
                        });
                    }
                },
            };
        };
        this.handleStreamCompletion = async (request) => {
            try {
                const streamTracker = this.streamStrackers.get(request.transactionId);
                if (!streamTracker) {
                    core_1.logger.warning("Stream tracker not found for transaction", {
                        transactionId: request.transactionId,
                    });
                    return;
                }
                const endTime = new Date();
                const duration = (0, core_1.calculateDurationMs)(request.startTime, endTime);
                const timeToFirstToken = request.firstTokenTime
                    ? (0, core_1.calculateDurationMs)(request.startTime, request.firstTokenTime)
                    : 0;
                const metering = new core_1.Metering();
                const meteringRequest = metering.createMeteringRequest({
                    modelName: this.modelName,
                    endTime,
                    startTime: request.startTime,
                    operationType: core_1.IOperationType.CHAT,
                    stopReason: "END",
                    tokenCounts: core_1.ESTIMATED_TOKEN_COUNTS,
                    usageMetadata: request.usageMetadata,
                });
                await metering.sendMeteringData(meteringRequest);
                this.streamStrackers.delete(request.transactionId);
                core_1.logger.info("Google AI stream completion metering completed", {
                    transactionId: request.transactionId,
                });
            }
            catch (error) {
                core_1.logger.error("Failed to handle stream completion metering", {
                    transactionId: request.transactionId,
                    error,
                });
                this.streamStrackers.delete(request.transactionId);
            }
        };
        this.generateEmbedding = async (request) => {
            if (!(0, core_1.verifyApiKey)() || !(0, core_1.verifyMeteringConfig)())
                return;
            core_1.logger.info("Google AI embedContent called");
            const startTime = new Date();
            const transactionId = (0, core_1.generateTransactionId)();
            const model = this.modelName;
            const usageMetadata = {};
            core_1.logger.info("Google AI embedContent called", {
                transactionId,
                model,
            });
            try {
                const params = typeof request === "string"
                    ? { model: this.modelName, contents: [request] }
                    : { ...request, model: this.modelName };
                const result = await this.client.models.embedContent(params);
                const stopReason = (0, core_1.extractStopReason)(result);
                const endTime = new Date();
                const metering = new core_1.Metering();
                const meteringRequest = metering.createMeteringRequest({
                    modelName: this.modelName,
                    endTime,
                    startTime,
                    operationType: core_1.IOperationType.EMBED,
                    stopReason,
                    tokenCounts: core_1.ESTIMATED_TOKEN_COUNTS,
                    usageMetadata,
                });
                await metering.sendMeteringData(meteringRequest);
                return result;
            }
            catch (error) {
                core_1.logger.error("Google AI embedContent failed", {
                    error,
                });
                throw error;
            }
        };
        this.apikey = clientApiKey !== null && clientApiKey !== void 0 ? clientApiKey : process.env.GOOGLE_API_KEY;
        this.client = new genai_1.GoogleGenAI({
            apiKey: (_b = (_a = this.apikey) !== null && _a !== void 0 ? _a : process.env.GOOGLE_API_KEY) !== null && _b !== void 0 ? _b : "",
        });
    }
    getGenerativeModel(modelPrams) {
        this.modelName = modelPrams.model;
        return {
            generateContent: this.generateContentMiddleware,
            generateContentStream: this.generateContentStream,
            embedContent: this.generateEmbedding,
        };
    }
}
exports.GoogleAiReveniumMiddleware = GoogleAiReveniumMiddleware;
